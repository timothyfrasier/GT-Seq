# Quality Filtering and Merging

There are a few things that we need to do next, that we can luckily all do at the same time using the program **fastp** (Chen et al. 2018). Below are some of the arguments that we will use, and an explanation of what they do.     
       `-merge`: for paired-end input, merge each pair of reads into a single read if they are overlapped.     
      `-merged_out`: specifies a file in which to store the merged reads.     
     * `-out1` `-out2`: Reads that can't be successfully merged, but which pass all filters.     
     * `-dont_eval_duplication`: We expect a lot of duplicates because these are amplicons, so we will disable evaluation of duplicates.     
     * `-detect_adapter_for_pe`: The adapter sequence auto-detection is enabled for single-end data only. Turn on this option to enable it for paired-end data.     
     * `average_qual 30`: Set the quality score threshold for reads. If read's average quality score is less than 30, read will be discarded.     
     * `thread 2`: Use 2 threads (default is 3)     
     * `-correction`: Enable base correction in overlapped regions (only for paired-end data), default is disabled.     
     * `-trim_poly_x`: Enable polyX trimming in 3' ends. This setting is useful for trimming the tails that have poliX (e.g., polyA).     
     * `-trim_poly_g`: Force polyG tail trimming. By default trimming is automatically enabled for Illumina NextSeq/NovaSeq data.     

Before we run this command, however, we need to organize things a bit for better processing and organization.

First, let's make a new directory for our output, and then navigate to it. I'll call it *filtered*.
```
mkdir filtered

cd filtered
```

Then, we need to make a list of all of the directory names that we can use to loop through, but only keep those that refer to samples. We will do this all in one line by piping the results from the `ls` command to a `grep` command that will just keep those lines that start with `Sample`.
```
ls ../ | grep "Sample_*" > files
```

Then we need to create a list of the sample files within each of these directories. To do this, create and open a new file, which we'll call *samples.sh* that will hold a script that we will run to do this.
```
nano samples.sh
```

What we want this script to do is go into each of the directories and list the contents. However, we only want the files that are associated with our samples. These can be differentiated because the have `_R1_` or `_R2_` in them (we just need one though, so we will select those with `R1`). The script should look like this.
```
#!/bin/bash

while read FILES;
do
  ls ../$FILES | grep "_R1_" >> names;
done < files
```

What this will do is list the contents of each of the directories listed in the *files* file, and the pipe those results to `grep`, which will search for just those lines that contain either `_R1_`. The output will be concatenated into a new file called *names*.

We next need to make this file an executable file.
```
chmod a+x samples.sh
```

Then we can run it.
```
./samples.sh
```

Take a look at the new *names* file to see that our script worked as expected.
```
less names
```

You will see that it is close to what we need, but that the `.md5` files are also included. We can remove them with the following command, which uses `grep` and the `-v` flag to keep all lines that **do not** contain the search term.
```
grep -v ".md5" names > names_kept
```

Take a look at this file and make sure it looks how you expect it to. You should have one line for each sample.
```
less names_kept

wc -l names_kept
```

For our next script to work, we need to capture just the part of the sample names prior to the `_R1`. There are probably a few ways that we can do this, but I will use `sed`. First I will replace `_R1_` with a tab.
```
sed -i "s/_R1_/\t/g" names_kept
```

Check that this did what you expected.
```
head names_kept
```

Then use the `cut` command to just keep the first column.
```
cut -f 1 names_kept > names_used
```

Check that this did what you expected.
```
head names_used
```


What we need to do next is write a script that will go into each of these directories and run **fastp** to perform the necessary filtering and merging actions, but then store the results in our new *filtered* directory.

First, create and open a new file (we'll call it "processing.sh") within which we will write our script.
```
nano processing.sh
```

Then, write the following lines within that file. Note that some of these names may change over time, so you should check every time and change as needed.
```
#!/bin/bash

#--- Loop through each sample in the file ---#
while read SAMPLE;
do

  SUB=$(echo "$SAMPLE" | awk -F _S '{ print $1 }')
  
  fastp --detect_adapter_for_pe --merge --merged_out ${SUB}_merged.fastq.gz --out1 ${SUB}_out1.fastq.gz --out2 ${SUB}_out2.fastq.gz --correction --dont_eval_duplication --average_qual 30 --trim_poly_g --trim_poly_x --html ${SUB}_test.html --thread 2 --in1 ../Sample_${SUB}/${SAMPLE}_R1_001.fastq.gz --in2 ../Sample_${SUB}/${SAMPLE}_R2_001.fastq.gz;
  
done < names_used
```

This is a bit complicated, so let's walk through it. The names being passed to this loop (from our *names_used* file) have the following format: `EGL00003-2_FRA2523A5-1_S46_L001`. This is the prefix for the read files for each sample. For this sample, they would be `EGL00003-2_FRA2523A5-1_S46_L001_R1_001.fastq.gz` and `EGL00003-2_FRA2523A5-1_S46_L001_R2_001.fastq.gz`. So we will need to add on the latter bits when we refer to the specific files. However, the directories that each of these file names is in is the first part of the file name (up until the `_S46` for this sample, but the number is different for different samples), but with `Sample_` as a prefix. So, for this sample, the directory that the files are in is called `Sample_EGL00003-2_FRA2523A5-1`.

The `while read SAMPLE...< names_used` part of this script is saying that for every line in the `names_used` file, refer to the text in that line as `SAMPLE`.

The `SUB=$(echo "$SAMPLE" | awk -F _S '{ print $1 }')` line uses the `awk` command to separate the text for each line at the point where there is a `_S`. The text *before* that occurs is considered the first column of the text, and we are printing that text to a new variable that we are calling `SUB`. In this way, for each step in the loop we have the general sample name `SUB`, as well as the fuller read file name other than the `_R1_001.fastq.gz` and `_R2_001.fastq.gz` suffixes, which is referred to as `SAMPLE`. 

The `fastp` line then calls **fastp**, with all of the arguments discussed above, naming the output files after the shorter sample name `SUB`, and then using these variable prefixes to process the correct files in the correct directories.


Then, make this script and executable file by typing the command below.
```
chmod a+x processing.sh
```

Then you can let it rip by typing
```
./processing.sh
```

After this is completed, it can give you some piece of mind to see how many merged reads to have for each sample (or in any other category). We can view the number of merged reads for each sample with the following command.
```
for file in *_merged.fastq.gz;
do
	echo $file;
	bioawk -c fastx 'END{print NR}' $file;
done
```

## References
Chen S, Zhou Y, Chen Y, Gu J (2018) fastp: an ultra-fast all-in-one FASTQ preprocessor. *Bioinformatics* **34**: i884--i890.
